{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T07:38:23.668315Z",
     "start_time": "2024-11-19T07:38:17.512442Z"
    }
   },
   "cell_type": "code",
   "source": "!poetry update -q",
   "id": "c8d46148ab432be6",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:53:29.812949Z",
     "start_time": "2024-11-19T08:53:29.807161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from configurations.cypher_chat_openai import CypherChatOpenAIConfiguration\n",
    "from configurations.neo4j import Neo4jConfiguration\n",
    "from configurations.configuration import Configuration\n",
    "from configurations.chat_openai import ChatOpenAIConfiguration\n",
    "\n",
    "configurations = Configuration.load('../configuration.yaml')\n",
    "neo4j = Neo4jConfiguration.grab(configurations)\n",
    "chat_openai = ChatOpenAIConfiguration.grab(configurations)\n",
    "cypher_chat_openai = CypherChatOpenAIConfiguration.grab(configurations)"
   ],
   "id": "9d795c1d9dac93b1",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:53:30.954982Z",
     "start_time": "2024-11-19T08:53:30.933504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from frames_benchmark_record import FramesBenchmarkRecord\n",
    "from load_csv import load_csv\n",
    "\n",
    "tests = load_csv('test.tsv', FramesBenchmarkRecord, delimiter='\\t')\n",
    "with open('imported_links.txt', 'r') as f:\n",
    "    imported_links = [line.strip() for line in f.readlines()]\n",
    "tests_for_imported: list[FramesBenchmarkRecord] = list(filter(lambda t: all((wiki_link in imported_links) for wiki_link in t.wiki_links), tests))"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:54:59.701343Z",
     "start_time": "2024-11-19T08:54:53.735125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "graph = Neo4jGraph(**neo4j.dict())\n",
    "CYPHER_GENERATION_TEMPLATE = f\"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "    Schema:\n",
    "    {{schema}}\n",
    "    Note: Do not include any explanations or apologies in your responses.\n",
    "    Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "    Do not include any text except the generated Cypher statement.\n",
    "    \n",
    "    The question is:\n",
    "    {{question}}\"\"\"\n",
    "\n",
    "CYPHER_GENERATION_PROMPT = PromptTemplate(input_variables=['schema', 'question'], validate_template=True, template=CYPHER_GENERATION_TEMPLATE)\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(**cypher_chat_openai.dict()),\n",
    "    cypher_prompt=CYPHER_GENERATION_PROMPT,\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    ")\n",
    "\n",
    "response = chain.invoke({'query': tests_for_imported[0].prompt})\n",
    "response"
   ],
   "id": "8850cfe04054b1be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new GraphCypherQAChain chain...\u001B[0m\n",
      "Generated Cypher:\n",
      "\u001B[32;1m\u001B[1;3mcypher\n",
      "MATCH (firstLady:Entity)-[:WAS_THE_SECOND_OF]->(mother:Entity)\n",
      "WHERE firstLady.name = \"Harriet Lane\"\n",
      "MATCH (president:Entity)-[:WAS_THE_SECOND_OF]->(mother2:Entity)\n",
      "WHERE president.name = \"James A. Garfield\"\n",
      "RETURN mother.name + \" \" + mother2.name AS futureWifeName\n",
      "\u001B[0m\n",
      "Full Context:\n",
      "\u001B[32;1m\u001B[1;3m[]\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': \"If my future wife has the same first name as the 15th first lady of the United States' mother and her surname is the same as the second assassinated president's mother's maiden name, what is my future wife's name? \",\n",
       " 'result': \"I don't know the answer.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T07:32:48.144958Z",
     "start_time": "2024-11-19T07:32:42.901835Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Question: «If my future wife has the same first name as the 15th first lady of the United States' mother and her surname is the same as the second assassinated president's mother's maiden name, what is my future wife's name?»\n",
      "- Predicted Answer: «Your future wife's name is Mary Mack. The 15th First Lady was Ellen Louise Wilson, and her mother's name was Mary. The second assassinated President was James A. Garfield, and his mother's maiden name was Eliza Ballou, so your wife's surname would be Mack, derived from the name of Garfield's maternal grandmother, Mary Mack.»\n",
      "- Ground Truth Answer: «Mary Mack»\n",
      "\n",
      "Explanation: The ground truth answer is \"Mary Mack.\" The predicted answer explains that the 15th First Lady's mother was named Mary and connects the surname Mack to the second assassinated president's family, concluding that the name would be Mary Mack. Although there is a more elaborate explanation in the predicted answer, the essential facts and the name \"Mary Mack\" are present, matching the ground truth answer.\n",
      "\n",
      "Decision: TRUE\n"
     ]
    }
   ],
   "execution_count": 9,
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "prompt = \"\"\"===Task===\n",
    "\n",
    "I need your help in evaluating an answer provided by an LLM against a ground truth answer. Your task is to determine if the ground truth answer is present in the LLM’s response. Please analyze the provided data and make a decision.\n",
    "===Instructions===\n",
    "1. Carefully compare the \"Predicted Answer\" with the \"Ground Truth Answer\".\n",
    "2. Consider the substance of the answers – look for equivalent information or correct answers. Do not focus on exact wording unless the exact wording is crucial to the meaning.\n",
    "3. Your final decision should be based on whether the meaning and the vital facts of the \"Ground Truth Answer\" are present in the \"Predicted Answer:\"\n",
    "\n",
    "===Input Data===\n",
    "- Question: «{question}»\n",
    "- Predicted Answer: «{answer}»\n",
    "- Ground Truth Answer: «{ground_truth}»\n",
    "\n",
    "===Output Format===\n",
    "Provide your final evaluation in the following format:\n",
    "\"Explanation:\" (How you made the decision?)\n",
    "\"Decision:\" (\"TRUE\" or \"FALSE\" )\n",
    "\n",
    "Please proceed with the evaluation. \"\"\"\n",
    "\n",
    "chat = ChatOpenAI(**chat_openai.dict())\n",
    "message = chat.invoke([\n",
    "    SystemMessage(content=prompt),\n",
    "    HumanMessage(content=tests_for_imported[0].prompt)\n",
    "])\n",
    "print(message.content)"
   ],
   "id": "e4697c5f90d05a28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# for t in tests:\n",
    "#     if all((wiki_link in imported_links) for wiki_link in t.wiki_links):\n",
    "#         print(t.id)"
   ],
   "id": "c78bd2031a3a1514"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
