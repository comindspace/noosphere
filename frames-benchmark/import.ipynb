{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "!poetry update -q",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_path = os.path.abspath('..')\n",
    "if project_path not in sys.path:\n",
    "    sys.path.insert(0, project_path)"
   ],
   "id": "d40da1337f258f47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from configurations.configuration import Configuration\n",
    "from configurations.chat_openai import ChatOpenAIConfiguration\n",
    "from configurations.cypher_chat_openai import CypherChatOpenAIConfiguration\n",
    "from configurations.neo4j import Neo4jConfiguration\n",
    "from configurations.openai_embeddings import OpenAIEmbeddingsConfiguration\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "configurations = Configuration.load('../configuration.yaml')\n",
    "neo4j = Neo4jConfiguration.grab(configurations)\n",
    "chat_openai = ChatOpenAIConfiguration.grab(configurations)\n",
    "openai_embeddings = OpenAIEmbeddingsConfiguration.grab(configurations)\n",
    "cypher_chat_openai = CypherChatOpenAIConfiguration.grab(configurations)"
   ],
   "id": "5c3858336451b6ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "f = 0\n",
    "t = 5"
   ],
   "id": "9ca10ac3d8f6ccd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "table = pq.read_table('train-00000-of-00001.parquet', memory_map=True)\n",
    "strings: list[str] = []\n",
    "imported_rows: list[str] = []\n",
    "for index, cell in enumerate(table[4][f:t]):\n",
    "    imported_rows.append(table[1][f + index].as_py())\n",
    "    strings.append(cell.as_py())"
   ],
   "id": "728b9cf5e063a7e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from sro import SRO\n",
    "\n",
    "llm = ChatOpenAI(**chat_openai.dict())\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Analyze the following text and extract all the facts in a structured way. Provide the facts in the format:\n",
    "\n",
    "Subject: SUBJECT OF FACT\n",
    "Relationship: TYPE OF RELATIONSHIP\n",
    "Object: FACT OBJECT\n",
    "\n",
    "Examples of facts:\n",
    "Subject: Alice, Relationship: works at, Object: Acme Corp.\n",
    "Subject: New York, Relationship: is, Object: city\n",
    "\n",
    "Text: \"{text}\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=prompt_template\n",
    ")\n",
    "\n",
    "entity_extraction_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "facts: list[str] = []\n",
    "for string in strings[f:t]:\n",
    "    # splitlines = string.splitlines()\n",
    "    # print(len(splitlines))\n",
    "    # for index, line in enumerate(splitlines):\n",
    "    #     print(index)\n",
    "    #     facts.append(entity_extraction_chain.run(line))\n",
    "    facts += entity_extraction_chain.run(string).split('\\n\\n')\n",
    "facts"
   ],
   "id": "c91d50179688f7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sros = list(filter(lambda sro: sro.is_full(), [SRO(fact) for fact in facts]))\n",
    "for sro in sros:\n",
    "    print(sro)"
   ],
   "id": "4a4d3343d164515a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "query = ''\n",
    "for index, sro in enumerate(sros):\n",
    "    query += f\"\"\"\n",
    "    MERGE (a{index}:Entity {{name: '{sro.subject}'}})\n",
    "    MERGE (b{index}:Entity {{name: '{sro.object}'}})\n",
    "    MERGE (a{index})-[:{sro.relation.replace(' ', '_').replace('-', '_').upper()}]->(b{index})\"\"\"\n",
    "graph = Neo4jGraph(**neo4j.dict())\n",
    "graph.query(query)\n",
    "\n",
    "with open('imported_links.txt', 'w') as file:\n",
    "    file.writelines([f\"{row}\\n\" for row in imported_rows])"
   ],
   "id": "3ec01b50b0dbe477",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
